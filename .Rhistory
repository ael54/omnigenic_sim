for(j in this.training.set){
this.my.G.training <- data.frame(row.names(list.of.subpopulation.QTN[[j]]),
list.of.subpopulation.QTN[[j]])
colnames(this.my.G.training)[1] <- "taxa"
if(counter == 0){
my.G.training <- this.my.G.training
}else{
my.G.training <- rbind(my.G.training, this.my.G.training)
}#end if(j == 1)
counter <- counter + 1
}#end for(j in 1:length(this.training.set))
}#end else
my.G.for.pipeline <- rbind(my.G.validation, my.G.training)
View(my.G.for.pipeline)
head(colnames(my.G.for.pipeline))
paste("X", this.simulated.trait$core.genes$core.genes, sep = ""))
paste("X", this.simulated.trait$core.genes$core.genes, sep = "")
my.G.for.pipeline.core <- my.G.for.pipeline[,c(1,which(colnames(my.G.for.pipeline) %in%
paste("X", this.simulated.trait$core.genes$core.genes, sep = "")))]
View(my.G.for.pipeline.core)
head(my.G.for.pipeline.core)
tail(my.G.for.pipeline.core)
mean(my.G.for.pipeline.core[,2])
frequency(my.G.for.pipeline.core[,2])
min(my.G.for.pipeline.core)
min(my.G.for.pipeline.core[,2])
max(my.G.for.pipeline.core[,2])
sum(my.G.for.pipeline.core[,2])
my.G.for.pipeline.peripheral <- my.G.for.pipeline[,c(1,-which(colnames(my.G.for.pipeline) %in%
paste("X", this.simulated.trait$core.genes$core.genes, sep = "")))]
my.G.for.pipeline.core <- my.G.for.pipeline[,which(colnames(my.G.for.pipeline) %in%
paste("X", this.simulated.trait$core.genes$core.genes, sep = ""))]
my.G.for.pipeline.peripheral <- my.G.for.pipeline[,-which(colnames(my.G.for.pipeline) %in%
paste("X", this.simulated.trait$core.genes$core.genes, sep = ""))]
dim(my.G.for.pipeline)
dim(my.G.for.pipeline.core)
dim(my.G.for.pipeline.peripheral)
#########################
#Read in a list of all lines that are in the validation population
taxa.in.validation <- my.Y.validation[,1]
dir.create("Results.multi.kernel.add.Test.20240326")
#Merge the genotypic data to the phenotypic data
#####################Turn this into a function
Y = my.Y.for.pipeline
traitname = this.trait.name
path.for.results = "Results.multi.kernel.add.Test.20240326/"
seed.number = 999
y <- as.matrix(Y[,-1])
G.core <- as.matrix(my.G.for.pipeline.core, nrow(y),
ncol(my.G.for.pipeline.core))
G.core <- G.core - 1
G.peripheral <- as.matrix(my.G.for.pipeline.peripheral, nrow(y),
ncol(my.G.for.pipeline.peripheral))
G.peripheral <- G.peripheral - 1
str(my.G.for.pipeline.peripheral)
my.G.for.pipeline.peripheral <- my.G.for.pipeline[,-which(colnames(my.G.for.pipeline) %in%
paste("X", this.simulated.trait$core.genes$core.genes, sep = ""))]
my.G.for.pipeline.peripheral <- my.G.for.pipeline[,-c(1,which(colnames(my.G.for.pipeline) %in%
paste("X", this.simulated.trait$core.genes$core.genes, sep = "")))]
G.peripheral <- as.matrix(my.G.for.pipeline.peripheral, nrow(y),
ncol(my.G.for.pipeline.peripheral))
G.peripheral <- G.peripheral - 1
#Set up the object CV, which needs to go along for the ride in rrBLUP
CV=Y[,1:2]
CV[,2]=1
colnames(CV)=c("taxa","overall")
cv <- (as.matrix(CV[,-1]))
taxa.names <- CV[,1]
#Calculate the partitioned kinship matrices (i.e., kernels)
A1.core <- A.mat(G.core)
colnames(A1.core) <- rownames(A1.core) <- c(1:nrow(y))
A1.peripheral <- A.mat(G.peripheral)
colnames(A1.peripheral) <- rownames(A1.peripheral) <- c(1:nrow(y))
sample.size <- nrow(y)
yNA <- y
yNA[pred] <- NA
yNA
tail(yNA)
#####data2 is for the double-kernel model. The additional columne, gid2 is needed
#########so that we can distinguish between the random effects corresponding to
########### each fo the two kernels
data2 <- data.frame(y=yNA,gid=1:length(y),gid2=1:length(y), cv = cv)
the.cv.names <- NULL
for(j in 1:ncol(cv)) the.cv.names <- c(the.cv.names, paste("CV_",j,sep = ""))
View(cv)
ncol(cv)
colnames(data2) <- c("y","gid", "gid2", the.cv.names)
data2$gid <- as.character(data2$gid)
data2$gid2 <- as.character(data2$gid2)
rownames(A1.core) <- 1:nrow(A1.core)
rownames(A1.peripheral) <- 1:nrow(A1.peripheral)
#Here is where the magic happens - this is where the two-kernel GS model is fitted
ans.multiple.kernel <- mmer(y~1, random = ~vsr(gid, Gu = A1.core)+vsr(gid2, Gu = A1.peripheral),
data = data2, verbose = FALSE)
GEBVs <- as.data.frame(ans.multiple.kernel$U$`u:gid`$y+
ans.multiple.kernel$U$`u:gid2`$y)
GEBVs  <- data.frame(as.numeric(rownames(GEBVs)), GEBVs )
View(GEBVs)
GEBVs <- GEBVs[order(GEBVs[,1]),]
pred
View(ans.multiple.kernel$U$`u:gid`$y)
tail(ans.multiple.kernel$U$`u:gid`$y)
#r.gy <- c(r.gy, cor(ans$g.pred,y[pred]))
r.gy <- cor(GEBVs[pred,2], y[pred])
r.gy
prediction.accuracy.GBLUP
source("QG_Analysis_Code/Run_GBLUP_Train_in_One_Pop_Validate_in_Another.R")
library(rrBLUP)
prediction.accuracy.GBLUP <- c(prediction.accuracy.GBLUP, r.gy)
####Standard GBLUP model
library(rrBLUP)
source("QG_Analysis_Code/Run_GBLUP_Train_in_One_Pop_Validate_in_Another.R")
source("QG_Analysis_Code/Run_GBLUP_Train_in_One_Pop_Validate_in_Another.R")
prediction.accuracy.GBLUP <- c(prediction.accuracy.GBLUP, r.gy)
source("QG_Analysis_Code/Run_GBLUP_Train_in_One_Pop_Validate_in_Another.R")
rm(list = ls())
#Set the working directory
setwd("/Users/alipka/Library/CloudStorage/Box-Box/Sabbatical_Roslin_Institute/R_workspace/Sabbatical_Project")
home.dir <- getwd()
###Read in the R workspace of simulated data
load("2.FactorA..0.05.FactorB..0.05.FactorC..0.05.FactorD..3.Rep.Rdata")
#Read in prerequiste libaries for GAPIT
library('MASS')
library(multtest)
library(gplots)
library(rrBLUP)
#Run a GWAS using a GLM for each subpopulation
list.of.subpopulation.traits <- list(directional.subpopulation.trait,
disruptive.subpopulation.trait,
stabilizing.subpopulation.trait)
list.of.subpopulation.QTN <- list(directional.subpopulation.QTNs,
disruptive.subpopulation.QTNs,
stabilizing.subpopulation.QTNs)
#list.of.subpopulation.SNPs <- list(directional.subpopulation.SNPs,
#                                   disruptive.subpopulation.SNPs,
#                                   stabilizing.subpopulation.SNPs)
names.of.subpopulations <- c("Directional.selection", "Disruptive.selection",
"Stabilizing.selection")
validation.set <- NULL
training.set.1 <- NULL
training.set.2 <- NULL
prediction.accuracy.GBLUP <- NULL
i <- 1
this.training.set <- this.training.set.1
#Choose a particular subpopulation to be the validation population
this.validation.set <- i
this.training.set.1 <- which(1:length(names.of.subpopulations)!= i)[1]
this.training.set.2 <- which(1:length(names.of.subpopulations)!= i)[2]
##################################################################
#Run genomic prediction using one of the other two populations as
# the training set
this.training.set <- this.training.set.1
validation.set <-c(validation.set, this.validation.set)
training.set.1 <- c(training.set.1, 1)
training.set.2 <- c(training.set.2, 0)
####Standard GBLUP model
source("QG_Analysis_Code/Run_GBLUP_Train_in_One_Pop_Validate_in_Another.R")
#Set the working directory
setwd("/Users/alipka/Library/CloudStorage/Box-Box/Sabbatical_Roslin_Institute/R_workspace/Sabbatical_Project")
home.dir <- getwd()
###Read in the R workspace of simulated data
load("2.FactorA..0.05.FactorB..0.05.FactorC..0.05.FactorD..3.Rep.Rdata")
#####Read in all of the packages that are necessary
#Read in prerequiste libaries for GAPIT
library('MASS')
library(multtest)
library(gplots)
library(rrBLUP)
#Read in GAPIT
setwd("Scripts_Necessary_for_GAPIT")
source("GAPIT_EMMA source code.txt")
source("GAPIT_Code_from_Internet_20120411_Allelic_Effect.r")
setwd(home.dir)
list.of.subpopulation.traits <- list(directional.subpopulation.trait,
disruptive.subpopulation.trait,
stabilizing.subpopulation.trait)
list.of.subpopulation.QTN <- list(directional.subpopulation.QTNs,
disruptive.subpopulation.QTNs,
stabilizing.subpopulation.QTNs)
#list.of.subpopulation.SNPs <- list(directional.subpopulation.SNPs,
#                                   disruptive.subpopulation.SNPs,
#                                   stabilizing.subpopulation.SNPs)
names.of.subpopulations <- c("Directional.selection", "Disruptive.selection",
"Stabilizing.selection")
validation.set <- NULL
training.set.1 <- NULL
training.set.2 <- NULL
prediction.accuracy.GBLUP <- NULL
this.validation.set <- i
this.training.set.1 <- which(1:length(names.of.subpopulations)!= i)[1]
this.training.set.2 <- which(1:length(names.of.subpopulations)!= i)[2]
##################################################################
#Run genomic prediction using one of the other two populations as
# the training set
this.training.set <- this.training.set.1
validation.set <-c(validation.set, this.validation.set)
training.set.1 <- c(training.set.1, 1)
training.set.2 <- c(training.set.2, 0)
####Standard GBLUP model
source("QG_Analysis_Code/Run_GBLUP_Train_in_One_Pop_Validate_in_Another.R")
prediction.accuracy.GBLUP <- c(prediction.accuracy.GBLUP, r.gy)
prediction.accuracy.Multi.Kern.No.Epi <- NULL
library(sommer)
prediction.accuracy.Multi.Kern.No.Epi <- NULL
#####Multi-kernel model where the additive effects of core and peripheral
# QTN are separate
source("Run_Multi_Kernel_BLUP_Add_Only.R")
#####Multi-kernel model where the additive effects of core and peripheral
# QTN are separate
source("QG_Analysis_Code/Run_Multi_Kernel_BLUP_Add_Only.R")
my.Y.validation <- data.frame(row.names(list.of.subpopulation.traits[[this.validation.set]]),
list.of.subpopulation.traits[[this.validation.set]])
colnames(my.Y.validation) <- c("taxa", "Trait")
if(length(this.training.set)==1){
my.Y.training <- data.frame(row.names(list.of.subpopulation.traits[[this.training.set]]),
list.of.subpopulation.traits[[this.training.set]])
colnames(my.Y.training) <- c("taxa", "Trait")
}else{
counter <- 0
for(j in this.training.set){
this.my.Y.training <- data.frame(row.names(list.of.subpopulation.traits[[j]]),
list.of.subpopulation.traits[[j]])
colnames(this.my.Y.training) <- c("taxa", "Trait")
if(counter == 0){
my.Y.training <- this.my.Y.training
}else{
my.Y.training <- rbind(my.Y.training, this.my.Y.training)
}#end if(j == 1)
counter <- counter+1
}#end for(j in 1:length(this.training.set))
}#end else
my.Y.for.pipeline <- rbind(my.Y.validation, my.Y.training)
this.trait.name <- colnames(my.Y.for.pipeline)[2]
#Read in the genotypic data
my.G.validation <- data.frame(row.names(list.of.subpopulation.QTN[[this.validation.set]]),
list.of.subpopulation.QTN[[this.validation.set]])
colnames(my.G.validation)[1] <- "taxa"
if(length(this.training.set)==1){
my.G.training <- data.frame(row.names(list.of.subpopulation.QTN[[this.training.set]]),
list.of.subpopulation.QTN[[this.training.set]])
colnames(my.G.training)[1] <- "taxa"
}else{
counter <- 0
for(j in this.training.set){
this.my.G.training <- data.frame(row.names(list.of.subpopulation.QTN[[j]]),
list.of.subpopulation.QTN[[j]])
colnames(this.my.G.training)[1] <- "taxa"
if(counter == 0){
my.G.training <- this.my.G.training
}else{
my.G.training <- rbind(my.G.training, this.my.G.training)
}#end if(j == 1)
counter <- counter + 1
}#end for(j in 1:length(this.training.set))
}#end else
my.G.for.pipeline <- rbind(my.G.validation, my.G.training)
my.G.for.pipeline.core <- my.G.for.pipeline[,which(colnames(my.G.for.pipeline) %in%
paste("X", this.simulated.trait$core.genes$core.genes, sep = ""))]
my.G.for.pipeline.peripheral <- my.G.for.pipeline[,-c(1,which(colnames(my.G.for.pipeline) %in%
paste("X", this.simulated.trait$core.genes$core.genes, sep = "")))]
#########################
#Read in a list of all lines that are in the validation population
taxa.in.validation <- my.Y.validation[,1]
dir.create("Results.multi.kernel.add.Test.20240326")
#Merge the genotypic data to the phenotypic data
#####################Turn this into a function
Y = my.Y.for.pipeline
traitname = this.trait.name
path.for.results = "Results.multi.kernel.add.Test.20240326/"
seed.number = 999
y <- as.matrix(Y[,-1])
G.core <- as.matrix(my.G.for.pipeline.core, nrow(y),
ncol(my.G.for.pipeline.core))
G.core <- G.core - 1
G.peripheral <- as.matrix(my.G.for.pipeline.peripheral, nrow(y),
ncol(my.G.for.pipeline.peripheral))
G.peripheral <- G.peripheral - 1
#Set up the object CV, which needs to go along for the ride in rrBLUP
CV=Y[,1:2]
CV[,2]=1
colnames(CV)=c("taxa","overall")
cv <- (as.matrix(CV[,-1]))
taxa.names <- CV[,1]
#Calculate the partitioned kinship matrices (i.e., kernels)
A1.core <- A.mat(G.core)
colnames(A1.core) <- rownames(A1.core) <- c(1:nrow(y))
A1.peripheral <- A.mat(G.peripheral)
colnames(A1.peripheral) <- rownames(A1.peripheral) <- c(1:nrow(y))
sample.size <- nrow(y)
pred <- which(taxa.names %in% taxa.in.validation)
yNA <- y
yNA[pred] <- NA
#####data2 is for the double-kernel model. The additional columne, gid2 is needed
#########so that we can distinguish between the random effects corresponding to
########### each fo the two kernels
data2 <- data.frame(y=yNA,gid=1:length(y),gid2=1:length(y), cv = cv)
the.cv.names <- NULL
for(j in 1:ncol(cv)) the.cv.names <- c(the.cv.names, paste("CV_",j,sep = ""))
colnames(data2) <- c("y","gid", "gid2", the.cv.names)
data2$gid <- as.character(data2$gid)
data2$gid2 <- as.character(data2$gid2)
rownames(A1.core) <- 1:nrow(A1.core)
rownames(A1.peripheral) <- 1:nrow(A1.peripheral)
#Here is where the magic happens - this is where the two-kernel GS model is fitted
ans.multiple.kernel <- mmer(y~1, random = ~vsr(gid, Gu = A1.core)+vsr(gid2, Gu = A1.peripheral),
data = data2, verbose = FALSE)
GEBVs <- as.data.frame(ans.multiple.kernel$U$`u:gid`$y+
ans.multiple.kernel$U$`u:gid2`$y)
GEBVs  <- data.frame(as.numeric(rownames(GEBVs)), GEBVs )
GEBVs <- GEBVs[order(GEBVs[,1]),]
.
#r.gy <- c(r.gy, cor(ans$g.pred,y[pred]))
r.gy.add.mult.kern <- cor(GEBVs[pred,2], y[pred])
r.gy.add.mult.kern
y[pred]
View(y[pred])
head(y[pred])
head(GEBVs[pred,2])
cor(GEBVs[pred,2], y[pred])
View(GEBVs)
View(GEBVs[pred,])
View(y[pred])
head(y[pred])
this.training.set
this.validation.set
i
i <- 1
#Choose a particular subpopulation to be the validation population
this.validation.set <- i
this.training.set.1 <- which(1:length(names.of.subpopulations)!= i)[1]
this.training.set.2 <- which(1:length(names.of.subpopulations)!= i)[2]
##################################################################
#Run genomic prediction using one of the other two populations as
# the training set
this.training.set <- this.training.set.1
validation.set <-c(validation.set, this.validation.set)
training.set.1 <- c(training.set.1, 1)
training.set.2 <- c(training.set.2, 0)
#####Multi-kernel model where the additive effects of core and peripheral
# QTN are separate
source("QG_Analysis_Code/Run_Multi_Kernel_BLUP_Add_Only.R")
prediction.accuracy.Multi.Kern.No.Epi <- c(prediction.accuracy.Multi.Kern.No.Epi,  r.gy.add.mult.kern)
prediction.accuracy.Multi.Kern.No.Epi
prediction.accuracy.GBLUP
i <- 2
this.validation.set <- i
this.training.set.1 <- which(1:length(names.of.subpopulations)!= i)[1]
this.training.set.2 <- which(1:length(names.of.subpopulations)!= i)[2]
##################################################################
#Run genomic prediction using one of the other two populations as
# the training set
this.training.set <- this.training.set.1
validation.set <-c(validation.set, this.validation.set)
training.set.1 <- c(training.set.1, 1)
training.set.2 <- c(training.set.2, 0)
source("QG_Analysis_Code/Run_Multi_Kernel_BLUP_Add_Only.R")
prediction.accuracy.Multi.Kern.No.Epi <- c(prediction.accuracy.Multi.Kern.No.Epi,  r.gy.add.mult.kern)
prediction.accuracy.Multi.Kern.No.Epi
prediction.accuracy.GBLUP
my.Y.validation <- data.frame(row.names(list.of.subpopulation.traits[[this.validation.set]]),
list.of.subpopulation.traits[[this.validation.set]])
colnames(my.Y.validation) <- c("taxa", "Trait")
if(length(this.training.set)==1){
my.Y.training <- data.frame(row.names(list.of.subpopulation.traits[[this.training.set]]),
list.of.subpopulation.traits[[this.training.set]])
colnames(my.Y.training) <- c("taxa", "Trait")
}else{
counter <- 0
for(j in this.training.set){
this.my.Y.training <- data.frame(row.names(list.of.subpopulation.traits[[j]]),
list.of.subpopulation.traits[[j]])
colnames(this.my.Y.training) <- c("taxa", "Trait")
if(counter == 0){
my.Y.training <- this.my.Y.training
}else{
my.Y.training <- rbind(my.Y.training, this.my.Y.training)
}#end if(j == 1)
counter <- counter+1
}#end for(j in 1:length(this.training.set))
}#end else
my.Y.for.pipeline <- rbind(my.Y.validation, my.Y.training)
this.trait.name <- colnames(my.Y.for.pipeline)[2]
#Read in the genotypic data
my.G.validation <- data.frame(row.names(list.of.subpopulation.QTN[[this.validation.set]]),
list.of.subpopulation.QTN[[this.validation.set]])
colnames(my.G.validation)[1] <- "taxa"
if(length(this.training.set)==1){
my.G.training <- data.frame(row.names(list.of.subpopulation.QTN[[this.training.set]]),
list.of.subpopulation.QTN[[this.training.set]])
colnames(my.G.training)[1] <- "taxa"
}else{
counter <- 0
for(j in this.training.set){
this.my.G.training <- data.frame(row.names(list.of.subpopulation.QTN[[j]]),
list.of.subpopulation.QTN[[j]])
colnames(this.my.G.training)[1] <- "taxa"
if(counter == 0){
my.G.training <- this.my.G.training
}else{
my.G.training <- rbind(my.G.training, this.my.G.training)
}#end if(j == 1)
counter <- counter + 1
}#end for(j in 1:length(this.training.set))
}#end else
my.G.for.pipeline <- rbind(my.G.validation, my.G.training)
my.G.for.pipeline.core <- my.G.for.pipeline[,which(colnames(my.G.for.pipeline) %in%
paste("X", this.simulated.trait$core.genes$core.genes, sep = ""))]
my.G.for.pipeline.peripheral <- my.G.for.pipeline[,-c(1,which(colnames(my.G.for.pipeline) %in%
paste("X", this.simulated.trait$core.genes$core.genes, sep = "")))]
#########################
#Read in a list of all lines that are in the validation population
taxa.in.validation <- my.Y.validation[,1]
#Temporary code: save my.Y, my.G.whole.genome, and taxa.in.282 into
# an R workspace to save some time required to read in "large" files
dir.create("Results.multi.kernel.add.Test.20240326")
#Merge the genotypic data to the phenotypic data
#####################Turn this into a function
Y = my.Y.for.pipeline
traitname = this.trait.name
path.for.results = "Results.multi.kernel.add.Test.20240326/"
seed.number = 999
y <- as.matrix(Y[,-1])
G.core <- as.matrix(my.G.for.pipeline.core, nrow(y),
ncol(my.G.for.pipeline.core))
G.core <- G.core - 1
G.peripheral <- as.matrix(my.G.for.pipeline.peripheral, nrow(y),
ncol(my.G.for.pipeline.peripheral))
G.peripheral <- G.peripheral - 1
#Set up the object CV, which needs to go along for the ride in rrBLUP
CV=Y[,1:2]
CV[,2]=1
colnames(CV)=c("taxa","overall")
cv <- (as.matrix(CV[,-1]))
taxa.names <- CV[,1]
#####The multi-kernel code differes starting here
#Partition G into two groups, depending on whether or not they are in the pathway of interest
#Calculate the partitioned kinship matrices (i.e., kernels)
A1.core <- A.mat(G.core)
colnames(A1.core) <- rownames(A1.core) <- c(1:nrow(y))
A1.peripheral <- A.mat(G.peripheral)
colnames(A1.peripheral) <- rownames(A1.peripheral) <- c(1:nrow(y))
X <- rbind(c(2,2), c(2,2))
Y <- rbind(c(4,4), c(4,4))
X
Y
X*Y
rm(X)
rm(Y)
A1.core.core <- A1.core*A1.core
View(A1.core)
View(A1.core.core)
A1.peripheral.peripheral <- A1.peripheral*A1.peripheral
A1.peripheral.peripheral <- A1.peripheral*A1.peripheral
A1.core.peripheral <- A1.core*A1.peripheral
dim(A1.core.core)
dim(A1.core.peripheral)
dim(A1.peripheral.peripheral)
length(y)
sample.size <- nrow(y)
pred <- which(taxa.names %in% taxa.in.validation)
yNA <- y
yNA[pred] <- NA
pred
#####data2 is for the double-kernel model. The additional columne, gid2 is needed
#########so that we can distinguish between the random effects corresponding to
########### each fo the two kernels
data2 <- data.frame(y=yNA,gid=1:length(y),gid2=1:length(y),gid3=1:length(y),
gid4 = 1:length(y), gid5 = 1:length(y), cv = cv)
the.cv.names <- NULL
for(j in 1:ncol(cv)) the.cv.names <- c(the.cv.names, paste("CV_",j,sep = ""))
#####data2 is for the double-kernel model. The additional columne, gid2 is needed
#########so that we can distinguish between the random effects corresponding to
########### each fo the two kernels
data2 <- data.frame(y=yNA,gid=1:length(y),gid2=1:length(y),gid3=1:length(y),
gid4 = 1:length(y), gid5 = 1:length(y), cv = cv)
the.cv.names <- NULL
for(j in 1:ncol(cv)) the.cv.names <- c(the.cv.names, paste("CV_",j,sep = ""))
colnames(data2) <- c("y","gid", "gid2","gid3","gid4", "gid5" the.cv.names)
colnames(data2) <- c("y","gid", "gid2","gid3","gid4", "gid5", the.cv.names)
data2$gid <- as.character(data2$gid)
data2$gid2 <- as.character(data2$gid2)
data2$gid3 <- as.character(data2$gid3)
data2$gid4 <- as.character(data2$gid4)
data2$gid5 <- as.character(data2$gid5)
rownames(A1.core) <- 1:nrow(A1.core)
rownames(A1.peripheral) <- 1:nrow(A1.peripheral)
rownames(A1.core.core) <- 1:nrow(A1.core.core)
rownames(A1.peripheral.peripheral) <- 1:nrow(A1.peripheral.peripheral)
rownames(A1.core.peripheral) <- 1:nrow(A1.core.peripheral)
#Here is where the magic happens - this is where the two-kernel GS model is fitted
ans.multiple.kernel <- mmer(y~1, random = ~vsr(gid, Gu = A1.core)+vsr(gid2, Gu = A1.peripheral)
+vsr(gid3, Gu = A1.core.core)+vsr(gid3, Gu = A1.peripheral.peripheral)
+vsr(gid3, Gu = A1.core.peripheral),
data = data2, verbose = FALSE)
ans.multiple.kernel <- mmer(y~1, random = ~vsr(gid, Gu = A1.core)+vsr(gid2, Gu = A1.peripheral)
+vsr(gid3, Gu = A1.core.core)+vsr(gid4, Gu = A1.peripheral.peripheral)
+vsr(gid5, Gu = A1.core.peripheral),
data = data2, verbose = FALSE)
GEBVs <- as.data.frame(ans.multiple.kernel$U$`u:gid`$y+
ans.multiple.kernel$U$`u:gid2`$y+
ans.multiple.kernel$U$`u:gid3`$y+
ans.multiple.kernel$U$`u:gid4`$y+
ans.multiple.kernel$U$`u:gid5`$y)
GEBVs  <- data.frame(as.numeric(rownames(GEBVs)), GEBVs )
GEBVs <- GEBVs[order(GEBVs[,1]),]
#r.gy <- c(r.gy, cor(ans$g.pred,y[pred]))
r.gy.add.epi.mult.kern <- cor(GEBVs[pred,2], y[pred])
r.gy.add.epi.mult.kern
prediction.accuracy.Multi.Kern.With.Epi <- NULL
#####Multi-kernel model where the additive and epistatic effects of core and peripheral
# QTN are separate
source("QG_Analysis_Code/Run_Multi_Kernel_BLUP_Add_and_Epi.R")
